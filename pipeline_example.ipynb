{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [SKTBrain/KoBERT](https://github.com/SKTBrain/KoBERT)\n",
    "- [eagle705/pytorch-bert-crf-ner](https://github.com/eagle705/pytorch-bert-crf-ner/blob/master/Visualization_BERT_NER.ipynb)\n",
    "- [BERT to the rescue!](https://towardsdatascience.com/bert-to-the-rescue-17671379687f)\n",
    "- [eagle705/pytorch-bert-crf-ner](https://github.com/eagle705/pytorch-bert-crf-ner/blob/master/data_utils/vocab_tokenizer.py)\n",
    "- [pytorch-pretrained-bert](https://pypi.org/project/pytorch-pretrained-bert/#usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(8002, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tqdm\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "font_dirs = ['/usr/share/fonts/truetype/nanum']\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "font_list = font_manager.createFontList(font_files)\n",
    "font_manager.fontManager.ttflist.extend(font_list)\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from gluonnlp.data import SentencepieceTokenizer\n",
    "from kobert.utils import get_tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import sentencepiece as spm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, vocab = get_pytorch_kobert_model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "/root/kobert/tokenizer_78b3253a26.model\n",
      "<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x7f684992fcf0> >\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer\n",
    "tok_path = get_tokenizer()\n",
    "print(tok_path)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "print(sp)\n",
    "sp.Load(tok_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "누가 기침소리를 내었는가 ? 누구인가 ?\n",
      "['[CLS]', '▁누가', '▁기', '침', '소리', '를', '▁내', '었', '는', '가', '▁?', '▁누구', '인', '가', '▁?', '[SEP]']\n",
      "[   2 1527 1258 7491 6609 6116 1434 6885 5760 5330  633 1528 7119 5330\n",
      "  633    3    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Tokenized input\n",
    "text = [\"누가 기침소리를 내었는가 ? 누구인가 ?\"]\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + sp.EncodeAsPieces(t) + ['[SEP]'], text))\n",
    "\n",
    "print(text[0])\n",
    "print(train_tokens[0])\n",
    "\n",
    "train_tokens_ids = pad_sequences(list(map(vocab.to_indices, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "print(train_tokens_ids[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_cores = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3429 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3429, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "100%|██████████| 3429/3429 [00:03<00:00, 887.67it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:01:00</td>\n",
       "      <td>50900</td>\n",
       "      <td>51100</td>\n",
       "      <td>50900</td>\n",
       "      <td>51000</td>\n",
       "      <td>580976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:02:00</td>\n",
       "      <td>51100</td>\n",
       "      <td>51100</td>\n",
       "      <td>50900</td>\n",
       "      <td>50900</td>\n",
       "      <td>46699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:03:00</td>\n",
       "      <td>51100</td>\n",
       "      <td>51100</td>\n",
       "      <td>51000</td>\n",
       "      <td>51100</td>\n",
       "      <td>13198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:04:00</td>\n",
       "      <td>51000</td>\n",
       "      <td>51100</td>\n",
       "      <td>51000</td>\n",
       "      <td>51100</td>\n",
       "      <td>37929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:05:00</td>\n",
       "      <td>51000</td>\n",
       "      <td>51100</td>\n",
       "      <td>50900</td>\n",
       "      <td>51000</td>\n",
       "      <td>83816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:17:00</td>\n",
       "      <td>52400</td>\n",
       "      <td>52500</td>\n",
       "      <td>52400</td>\n",
       "      <td>52500</td>\n",
       "      <td>12420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:18:00</td>\n",
       "      <td>52500</td>\n",
       "      <td>52500</td>\n",
       "      <td>52400</td>\n",
       "      <td>52400</td>\n",
       "      <td>20269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:19:00</td>\n",
       "      <td>52500</td>\n",
       "      <td>52500</td>\n",
       "      <td>52400</td>\n",
       "      <td>52500</td>\n",
       "      <td>18480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:20:00</td>\n",
       "      <td>52500</td>\n",
       "      <td>52500</td>\n",
       "      <td>52400</td>\n",
       "      <td>52500</td>\n",
       "      <td>47526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:30:00</td>\n",
       "      <td>52600</td>\n",
       "      <td>52600</td>\n",
       "      <td>52600</td>\n",
       "      <td>52600</td>\n",
       "      <td>832746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3429 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     close   high    low   open     vol\n",
       "time                                                   \n",
       "2019-10-31 09:01:00  50900  51100  50900  51000  580976\n",
       "2019-10-31 09:02:00  51100  51100  50900  50900   46699\n",
       "2019-10-31 09:03:00  51100  51100  51000  51100   13198\n",
       "2019-10-31 09:04:00  51000  51100  51000  51100   37929\n",
       "2019-10-31 09:05:00  51000  51100  50900  51000   83816\n",
       "...                    ...    ...    ...    ...     ...\n",
       "2019-11-12 15:17:00  52400  52500  52400  52500   12420\n",
       "2019-11-12 15:18:00  52500  52500  52400  52400   20269\n",
       "2019-11-12 15:19:00  52500  52500  52400  52500   18480\n",
       "2019-11-12 15:20:00  52500  52500  52400  52500   47526\n",
       "2019-11-12 15:30:00  52600  52600  52600  52600  832746\n",
       "\n",
       "[3429 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and preprocess\n",
    "price = pd.read_csv('data/example/price_005930.csv', index_col=0)\n",
    "print(price.shape)\n",
    "\n",
    "'''\n",
    "# convert timestamp of price dataframe as datetime object\n",
    "pool = multiprocessing.pool.ThreadPool(num_of_cores)\n",
    "args = list(range(price.shape[0]))\n",
    "def price_to_datetime(i) : \n",
    "    price['time'].iloc[i] = pd.to_datetime(str(price['date'].iloc[i])+str(price['time'].iloc[i]), format='%Y%m%d%H%M')\n",
    "    pbar.update(1)\n",
    "    return\n",
    "with tqdm.tqdm(total=len(args)) as pbar:\n",
    "    for i in range(len(args)):\n",
    "        pool.apply_async(price_to_datetime, [args[i]])\n",
    "    pool.close()\n",
    "    pool.join()       \n",
    "'''\n",
    "# convert timestamp of price dataframe as datetime object\n",
    "with tqdm.tqdm(total=price.shape[0]) as pbar :\n",
    "    for i in range(price.shape[0]) : \n",
    "        price['time'].iloc[i] = pd.to_datetime(str(price['date'].iloc[i])+str(price['time'].iloc[i]), format='%Y%m%d%H%M')\n",
    "        pbar.update(1)   \n",
    "# sort in ascending order\n",
    "price = price.sort_values(by='time').reset_index(drop=True)\n",
    "price.index = price['time']\n",
    "price = price.drop(['date', 'time'], axis=1)\n",
    "display(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 75/20129 [00:00<00:27, 742.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20129, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 17614/20129 [00:24<00:03, 706.60it/s]"
     ]
    }
   ],
   "source": [
    "# Load and preprocess\n",
    "reply = pd.read_csv('data/example/reply_005930.csv', index_col=0).reset_index(drop=True)\n",
    "print(reply.shape)\n",
    "\n",
    "# wrong data in the dataframe\n",
    "#display(pd.DataFrame(reply.iloc[209]).T)\n",
    "#display(pd.DataFrame(reply.iloc[210]).T)\n",
    "\n",
    "'''\n",
    "# convert timestamp of reply dataframe as datetime object, drop wrong rows\n",
    "list_to_drop = []\n",
    "pool = multiprocessing.pool.ThreadPool(num_of_cores)\n",
    "args = list(range(reply.shape[0]))\n",
    "def reply_to_datetime(i) : \n",
    "    try : \n",
    "        reply['Date'].iloc[i] = pd.to_datetime(reply['Date'].iloc[i], format='%Y.%m.%d %H:%M')\n",
    "        pbar.update(1)\n",
    "    except Exception as e :\n",
    "        list_to_drop.append(i)\n",
    "        pbar.update(1)\n",
    "    return\n",
    "with tqdm.tqdm(total=len(args)) as pbar:\n",
    "    for i in range(len(args)):\n",
    "        pool.apply_async(reply_to_datetime, [args[i]])\n",
    "    pool.close()\n",
    "    pool.join() \n",
    "'''\n",
    "# convert timestamp of reply dataframe as datetime object, drop wrong rows\n",
    "list_to_drop = []\n",
    "with tqdm.tqdm(total=reply.shape[0]) as pbar : \n",
    "    for i in range(reply.shape[0]) : \n",
    "        try : \n",
    "            reply['Date'].iloc[i] = pd.to_datetime(reply['Date'].iloc[i], format='%Y.%m.%d %H:%M')\n",
    "            pbar.update(1)\n",
    "        except Exception as e :\n",
    "            list_to_drop.append(i)\n",
    "            pbar.update(1)\n",
    "reply = reply.drop(list_to_drop, axis=0)\n",
    "      \n",
    "# sort in ascending order\n",
    "reply = reply.sort_values(by='Date').reset_index(drop=True)\n",
    "reply.index = reply['Date']\n",
    "reply = reply.drop(['Date'], axis=1)\n",
    "\n",
    "display(reply[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_start = max(price.index[0], reply.index[0])\n",
    "day_end = min(price.index[-1], reply.index[-1])\n",
    "print(day_start)\n",
    "print(day_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframe\n",
    "reply_common = reply[(reply.index >= day_start) & (reply.index <= day_end)]\n",
    "price_common = price[(price.index >= day_start) & (price.index <= day_end)]\n",
    "df = reply_common.merge(price_common, how='outer', left_on=reply_common.index, right_on=price_common.index)\n",
    "df.index = df['key_0']\n",
    "df = df.drop(['key_0'], axis=1)\n",
    "display(df)\n",
    "\n",
    "# check intersection of timestamp\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(price.index, np.zeros(price.shape[0]), label='price')\n",
    "plt.plot(reply.index, np.ones(reply.shape[0]), label='reply')\n",
    "plt.plot(df.index, np.full(df.shape[0], 2), label='merged df')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부탁드릴 내용\n",
    "- 제목 미리보기?\n",
    "    - '오늘 실적발표 일...'\n",
    "    - 페이지에 들어가서 잘리지 않은 제목으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urlextract import URLExtract\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tag(content) : \n",
    "    return content.replace('\\r', '').replace('\\n', '').replace('\\\\', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_link(content): \n",
    "    extractor = URLExtract()\n",
    "    urls = extractor.find_urls(content)\n",
    "    for url in urls : \n",
    "        content = content.replace(url, '링크')\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_punctuation(content) : \n",
    "    return content.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbers(content) : \n",
    "    content = content.replace('만원', '0000')\n",
    "    return content, [int(x) for x in re.findall('\\d+', content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 0.1\n",
    "# price in txt가 close와 얼마나 비슷한지 확인하고, 너무 차이나면 관계없는 숫자이기때문에 걸러야 함\n",
    "# price in txt의 dimension도 확인하고, 너무 많을 경우 의미없는 숫자들일 가능성이 큼\n",
    "def get_price_in_txt(numbers_in_txt, close) : \n",
    "    if len(numbers_in_txt) == 1 :\n",
    "        number_in_txt = numbers_in_txt[0]\n",
    "        if (number_in_txt <= close * (1+band)) and (number_in_txt >= close * (1-band)) :\n",
    "            return number_in_txt\n",
    "        else : \n",
    "            return -1\n",
    "    else :\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(text, close) : \n",
    "    bypass = replace_tag(text)\n",
    "    bypass = replace_link(bypass)\n",
    "    bypass = replace_punctuation(bypass)\n",
    "    bypass, numbers_in_txt = get_numbers(bypass)\n",
    "    price_in_txt = get_price_in_txt(numbers_in_txt, close)\n",
    "    \n",
    "    return bypass, price_in_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "close = df['close'][idx]\n",
    "text = df['Title'][idx]\n",
    "bypass, price_in_txt = preprocess_pipeline(text, close)\n",
    "print(bypass)\n",
    "print(close, price_in_txt)\n",
    "\n",
    "# Tokenized input\n",
    "bypass = [bypass]\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + sp.EncodeAsPieces(t) + ['[SEP]'], bypass))\n",
    "print(train_tokens[0])\n",
    "train_tokens_ids = pad_sequences(list(map(vocab.to_indices, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "print(train_tokens_ids[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 31\n",
    "close = df['close'][idx]\n",
    "text = df['Content'][idx]\n",
    "bypass, price_in_txt = preprocess_pipeline(text, close)\n",
    "print(bypass)\n",
    "print(close, price_in_txt)\n",
    "\n",
    "# Tokenized input\n",
    "bypass = [bypass]\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + sp.EncodeAsPieces(t) + ['[SEP]'], bypass))\n",
    "print(train_tokens[0])\n",
    "train_tokens_ids = pad_sequences(list(map(vocab.to_indices, train_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "print(train_tokens_ids[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_content(idx) : \n",
    "    close = df['close'][idx]\n",
    "    title = df['Title'][idx]\n",
    "    content = df['Content'][idx]\n",
    "    \n",
    "    bypass_title, price_in_title = preprocess_pipeline(title, close)\n",
    "    bypass_content, price_in_content = preprocess_pipeline(content, close)\n",
    "    \n",
    "    df['Title'].iloc[idx] = bypass_title\n",
    "    df['Content'].iloc[idx] = bypass_content\n",
    "    \n",
    "    if df['PriceInTxt'].iloc[idx] == -1 : \n",
    "        df['PriceInTxt'].iloc[idx] = price_in_title\n",
    "    if df['PriceInTxt'].iloc[idx] == -1 : \n",
    "        df['PriceInTxt'].iloc[idx] = price_in_content\n",
    "    pbar.update(1)\n",
    "    return\n",
    "\n",
    "df['PriceInTxt'] = -1\n",
    "preprocess_content(0)\n",
    "display(df[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamp of price dataframe as datetime object\n",
    "pool = multiprocessing.pool.ThreadPool(num_of_cores)\n",
    "args = list(range(df.shape[0]))\n",
    "df['PriceInTxt'] = -1\n",
    "\n",
    "with tqdm.tqdm(total=len(args)) as pbar:\n",
    "    for i in range(len(args)):\n",
    "        pool.apply_async(preprocess_content, [args[i]])\n",
    "    pool.close()\n",
    "    pool.join()       \n",
    "    \n",
    "df.to_pickle('data/example/preprocessed_005930.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.select_dtypes('float64').columns\n",
    "for column in columns : \n",
    "    df[column] = df[column].astype('Int64')\n",
    "\n",
    "df.to_pickle('data/example/preprocessed_005930.pkl')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/example/preprocessed_005930.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertRegressor(nn.Module) : \n",
    "    def __init__(self) : \n",
    "        super(BertRegressor, self).__init__()\n",
    "        self.bert, self.vocab = get_pytorch_kobert_model()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "    \n",
    "    def forward(self, tokens) : \n",
    "        _, pooled_output = self.bert(tokens, utput_all=False)\n",
    "        linear_output = self.relu(pooled_output)\n",
    "        predicted_price = self.linear(linear_output)\n",
    "\n",
    "        return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_reg = BertRegressor()\n",
    "bert_reg.to(device)\n",
    "optimizer = torch.optim.Adam(bert_reg.parameters(), lr=3e-6)\n",
    "bert_reg.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
