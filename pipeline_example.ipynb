{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [SKTBrain/KoBERT](https://github.com/SKTBrain/KoBERT)\n",
    "- [eagle705/pytorch-bert-crf-ner](https://github.com/eagle705/pytorch-bert-crf-ner/blob/master/Visualization_BERT_NER.ipynb)\n",
    "- [BERT to the rescue!](https://towardsdatascience.com/bert-to-the-rescue-17671379687f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(8002, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "font_dirs = ['/usr/share/fonts/truetype/nanum']\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "font_list = font_manager.createFontList(font_files)\n",
    "font_manager.fontManager.ttflist.extend(font_list)\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from gluonnlp.data import SentencepieceTokenizer\n",
    "from kobert.utils import get_tokenizer\n",
    "import sentencepiece as spm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, vocab = get_pytorch_kobert_model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "/root/kobert/tokenizer_78b3253a26.model\n",
      "<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x7fcc54896660> >\n",
      "누가 기침소리를 내었는가 ? 누구인가 ?\n",
      "['▁누가', '▁기', '침', '소리', '를', '▁내', '었', '는', '가', '▁?', '▁누구', '인', '가', '▁?']\n",
      "[1527, 1258, 7491, 6609, 6116, 1434, 6885, 5760, 5330, 633, 1528, 7119, 5330, 633]\n",
      "['▁누가', '▁기', '침', '소리', '를', '▁내', '었', '는', '가', '▁?', '▁누구', '인', '가', '▁?']\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer\n",
    "tok_path = get_tokenizer()\n",
    "print(tok_path)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "print(sp)\n",
    "sp.Load(tok_path)\n",
    "\n",
    "# Tokenized input\n",
    "#text = \"[CLS] 누가 기침소리를 내었는가 ? [SEP] 누구인가 ? [SEP]\"\n",
    "text = \"누가 기침소리를 내었는가 ? 누구인가 ?\"\n",
    "tokenized_text = sp.EncodeAsPieces(text)\n",
    "indexed_tokens = vocab.to_indices(tokenized_text)\n",
    "reconstructed = vocab.to_tokens(indexed_tokens)\n",
    "\n",
    "print(text)\n",
    "print(tokenized_text)\n",
    "print(indexed_tokens)\n",
    "print(reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 78/20129 [00:00<00:25, 779.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20129, 7)\n",
      "(3429, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20129/20129 [00:27<00:00, 741.32it/s]\n",
      "100%|██████████| 3429/3429 [00:03<00:00, 906.45it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Views</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Like</th>\n",
       "      <th>Unlike</th>\n",
       "      <th>Ip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-10-08 11:22:00</td>\n",
       "      <td>93</td>\n",
       "      <td>홍어도</td>\n",
       "      <td>홍어  먹으로  가야는되  어느지역으로  가야 하냐알려다오   홍어도  사람들아</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.38.***.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-08 11:23:00</td>\n",
       "      <td>67</td>\n",
       "      <td>[삭제된 게시물의 답글]박원숭   렉서스 잘굴러가냐??</td>\n",
       "      <td>아들은 찾았고?? 딸는 아직도  돈많이든다는 스위스 유학중이고??? 미누라 일감은 ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.139.***.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-08 11:27:00</td>\n",
       "      <td>108</td>\n",
       "      <td>자격없는 문재인 때문에</td>\n",
       "      <td>나라가 요지경 \\r\\r\\nㅂㅅ 문재인</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>58.238.***.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-08 11:28:00</td>\n",
       "      <td>103</td>\n",
       "      <td>박원순   사람이 5명이나 죽었다  니가 불렀자나??</td>\n",
       "      <td>니가 불렀자나??? 니가 그런거자나????   책임져야하자나??? 양심은 어따팔아...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.139.***.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-08 11:29:00</td>\n",
       "      <td>116</td>\n",
       "      <td>검찰, '갑자기 허리 수술' 조국 동생 부산서 강제 구인...!</td>\n",
       "      <td>영장심사 오후에 열릴 듯--조선일보</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.114.***.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 23:32:00</td>\n",
       "      <td>22</td>\n",
       "      <td>아베  자서전</td>\n",
       "      <td>아베가\\r\\r\\n자기 조상이\\r\\r\\n즐라 홍어인 이라고 자서전에서 고백\\r\\r\\n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.86.***.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 23:34:00</td>\n",
       "      <td>15</td>\n",
       "      <td>아베는 백제 씨다 딱 보면 이낙연도 백제 사람은 뽐내기를 좋아하는</td>\n",
       "      <td>부산사람과 속 마음자체가 달라 마음속 가치를 중시한다 점 잖은 사람을 더 좋아 한다</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.227.***.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 23:34:00</td>\n",
       "      <td>41</td>\n",
       "      <td>개떡치는 미증시 정신업따 ㅋ</td>\n",
       "      <td>애플 연일 신고가 행진 ㅋ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.199.***.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 23:36:00</td>\n",
       "      <td>21</td>\n",
       "      <td>문재인 보니 이제 좀 알겠니?</td>\n",
       "      <td>빨갱이들은 남의 돈 뺐는게 직업이라는거?\\r\\r\\n \\r\\n그 개씨x새끼가 의료보험...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.7.***.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 23:36:00</td>\n",
       "      <td>11</td>\n",
       "      <td>문씨는 부산사람들 얄팍하고 뽐내기를 좋아한다 이게 사람 질이 틀려</td>\n",
       "      <td>딱 보면 느낌이 달라</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.227.***.123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19980 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Views                                 Title  \\\n",
       "Date                                                               \n",
       "2019-10-08 11:22:00     93                                   홍어도   \n",
       "2019-10-08 11:23:00     67        [삭제된 게시물의 답글]박원숭   렉서스 잘굴러가냐??   \n",
       "2019-10-08 11:27:00    108                          자격없는 문재인 때문에   \n",
       "2019-10-08 11:28:00    103         박원순   사람이 5명이나 죽었다  니가 불렀자나??   \n",
       "2019-10-08 11:29:00    116   검찰, '갑자기 허리 수술' 조국 동생 부산서 강제 구인...!   \n",
       "...                    ...                                   ...   \n",
       "2019-11-12 23:32:00     22                               아베  자서전   \n",
       "2019-11-12 23:34:00     15  아베는 백제 씨다 딱 보면 이낙연도 백제 사람은 뽐내기를 좋아하는   \n",
       "2019-11-12 23:34:00     41                       개떡치는 미증시 정신업따 ㅋ   \n",
       "2019-11-12 23:36:00     21                      문재인 보니 이제 좀 알겠니?   \n",
       "2019-11-12 23:36:00     11  문씨는 부산사람들 얄팍하고 뽐내기를 좋아한다 이게 사람 질이 틀려   \n",
       "\n",
       "                                                               Content  Like  \\\n",
       "Date                                                                           \n",
       "2019-10-08 11:22:00       홍어  먹으로  가야는되  어느지역으로  가야 하냐알려다오   홍어도  사람들아   1.0   \n",
       "2019-10-08 11:23:00  아들은 찾았고?? 딸는 아직도  돈많이든다는 스위스 유학중이고??? 미누라 일감은 ...   4.0   \n",
       "2019-10-08 11:27:00                               나라가 요지경 \\r\\r\\nㅂㅅ 문재인   8.0   \n",
       "2019-10-08 11:28:00   니가 불렀자나??? 니가 그런거자나????   책임져야하자나??? 양심은 어따팔아...   4.0   \n",
       "2019-10-08 11:29:00                                영장심사 오후에 열릴 듯--조선일보   8.0   \n",
       "...                                                                ...   ...   \n",
       "2019-11-12 23:32:00  아베가\\r\\r\\n자기 조상이\\r\\r\\n즐라 홍어인 이라고 자서전에서 고백\\r\\r\\n...   0.0   \n",
       "2019-11-12 23:34:00     부산사람과 속 마음자체가 달라 마음속 가치를 중시한다 점 잖은 사람을 더 좋아 한다   0.0   \n",
       "2019-11-12 23:34:00                                     애플 연일 신고가 행진 ㅋ   2.0   \n",
       "2019-11-12 23:36:00  빨갱이들은 남의 돈 뺐는게 직업이라는거?\\r\\r\\n \\r\\n그 개씨x새끼가 의료보험...   1.0   \n",
       "2019-11-12 23:36:00                                        딱 보면 느낌이 달라   0.0   \n",
       "\n",
       "                     Unlike              Ip  \n",
       "Date                                         \n",
       "2019-10-08 11:22:00     0.0  223.38.***.169  \n",
       "2019-10-08 11:23:00     0.0  125.139.***.71  \n",
       "2019-10-08 11:27:00     4.0   58.238.***.52  \n",
       "2019-10-08 11:28:00     0.0  125.139.***.71  \n",
       "2019-10-08 11:29:00     0.0  211.114.***.78  \n",
       "...                     ...             ...  \n",
       "2019-11-12 23:32:00     0.0   115.86.***.36  \n",
       "2019-11-12 23:34:00     0.0   1.227.***.123  \n",
       "2019-11-12 23:34:00     0.0  124.199.***.50  \n",
       "2019-11-12 23:36:00     2.0    39.7.***.244  \n",
       "2019-11-12 23:36:00     2.0   1.227.***.123  \n",
       "\n",
       "[19980 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>time</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:01:00</td>\n",
       "      <td>50900</td>\n",
       "      <td>20191031</td>\n",
       "      <td>51100</td>\n",
       "      <td>50900</td>\n",
       "      <td>51000</td>\n",
       "      <td>2019-10-31 09:01:00</td>\n",
       "      <td>580976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:02:00</td>\n",
       "      <td>51100</td>\n",
       "      <td>20191031</td>\n",
       "      <td>51100</td>\n",
       "      <td>50900</td>\n",
       "      <td>50900</td>\n",
       "      <td>2019-10-31 09:02:00</td>\n",
       "      <td>46699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:03:00</td>\n",
       "      <td>51100</td>\n",
       "      <td>20191031</td>\n",
       "      <td>51100</td>\n",
       "      <td>51000</td>\n",
       "      <td>51100</td>\n",
       "      <td>2019-10-31 09:03:00</td>\n",
       "      <td>13198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:04:00</td>\n",
       "      <td>51000</td>\n",
       "      <td>20191031</td>\n",
       "      <td>51100</td>\n",
       "      <td>51000</td>\n",
       "      <td>51100</td>\n",
       "      <td>2019-10-31 09:04:00</td>\n",
       "      <td>37929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:05:00</td>\n",
       "      <td>51000</td>\n",
       "      <td>20191031</td>\n",
       "      <td>51100</td>\n",
       "      <td>50900</td>\n",
       "      <td>51000</td>\n",
       "      <td>2019-10-31 09:05:00</td>\n",
       "      <td>83816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:17:00</td>\n",
       "      <td>52400</td>\n",
       "      <td>20191112</td>\n",
       "      <td>52500</td>\n",
       "      <td>52400</td>\n",
       "      <td>52500</td>\n",
       "      <td>2019-11-12 15:17:00</td>\n",
       "      <td>12420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:18:00</td>\n",
       "      <td>52500</td>\n",
       "      <td>20191112</td>\n",
       "      <td>52500</td>\n",
       "      <td>52400</td>\n",
       "      <td>52400</td>\n",
       "      <td>2019-11-12 15:18:00</td>\n",
       "      <td>20269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:19:00</td>\n",
       "      <td>52500</td>\n",
       "      <td>20191112</td>\n",
       "      <td>52500</td>\n",
       "      <td>52400</td>\n",
       "      <td>52500</td>\n",
       "      <td>2019-11-12 15:19:00</td>\n",
       "      <td>18480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:20:00</td>\n",
       "      <td>52500</td>\n",
       "      <td>20191112</td>\n",
       "      <td>52500</td>\n",
       "      <td>52400</td>\n",
       "      <td>52500</td>\n",
       "      <td>2019-11-12 15:20:00</td>\n",
       "      <td>47526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:30:00</td>\n",
       "      <td>52600</td>\n",
       "      <td>20191112</td>\n",
       "      <td>52600</td>\n",
       "      <td>52600</td>\n",
       "      <td>52600</td>\n",
       "      <td>2019-11-12 15:30:00</td>\n",
       "      <td>832746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3429 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     close      date   high    low   open  \\\n",
       "time                                                        \n",
       "2019-10-31 09:01:00  50900  20191031  51100  50900  51000   \n",
       "2019-10-31 09:02:00  51100  20191031  51100  50900  50900   \n",
       "2019-10-31 09:03:00  51100  20191031  51100  51000  51100   \n",
       "2019-10-31 09:04:00  51000  20191031  51100  51000  51100   \n",
       "2019-10-31 09:05:00  51000  20191031  51100  50900  51000   \n",
       "...                    ...       ...    ...    ...    ...   \n",
       "2019-11-12 15:17:00  52400  20191112  52500  52400  52500   \n",
       "2019-11-12 15:18:00  52500  20191112  52500  52400  52400   \n",
       "2019-11-12 15:19:00  52500  20191112  52500  52400  52500   \n",
       "2019-11-12 15:20:00  52500  20191112  52500  52400  52500   \n",
       "2019-11-12 15:30:00  52600  20191112  52600  52600  52600   \n",
       "\n",
       "                                    time     vol  \n",
       "time                                              \n",
       "2019-10-31 09:01:00  2019-10-31 09:01:00  580976  \n",
       "2019-10-31 09:02:00  2019-10-31 09:02:00   46699  \n",
       "2019-10-31 09:03:00  2019-10-31 09:03:00   13198  \n",
       "2019-10-31 09:04:00  2019-10-31 09:04:00   37929  \n",
       "2019-10-31 09:05:00  2019-10-31 09:05:00   83816  \n",
       "...                                  ...     ...  \n",
       "2019-11-12 15:17:00  2019-11-12 15:17:00   12420  \n",
       "2019-11-12 15:18:00  2019-11-12 15:18:00   20269  \n",
       "2019-11-12 15:19:00  2019-11-12 15:19:00   18480  \n",
       "2019-11-12 15:20:00  2019-11-12 15:20:00   47526  \n",
       "2019-11-12 15:30:00  2019-11-12 15:30:00  832746  \n",
       "\n",
       "[3429 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and preprocess\n",
    "reply = pd.read_csv('data/example/reply_005930.csv', index_col=0).reset_index(drop=True)\n",
    "price = pd.read_csv('data/example/price_005930.csv', index_col=0)\n",
    "print(reply.shape)\n",
    "#display(reply[0:2])\n",
    "print(price.shape)\n",
    "#display(price[0:5])\n",
    "\n",
    "# wrong data in the dataframe\n",
    "#display(pd.DataFrame(reply.iloc[209]).T)\n",
    "#display(pd.DataFrame(reply.iloc[210]).T)\n",
    "\n",
    "# convert timestamp of reply dataframe as datetime object, drop wrong rows\n",
    "list_to_drop = []\n",
    "with tqdm.tqdm(total=reply.shape[0]) as pbar : \n",
    "    for i in range(reply.shape[0]) : \n",
    "        try : \n",
    "            reply['Date'].iloc[i] = pd.to_datetime(reply['Date'].iloc[i], format='%Y.%m.%d %H:%M')\n",
    "            pbar.update(1)\n",
    "        except Exception as e :\n",
    "            list_to_drop.append(i)\n",
    "            pbar.update(1)\n",
    "reply = reply.drop(list_to_drop, axis=0)\n",
    "        \n",
    "# convert timestamp of price dataframe as datetime object\n",
    "with tqdm.tqdm(total=price.shape[0]) as pbar :\n",
    "    for i in range(price.shape[0]) : \n",
    "        price['time'].iloc[i] = pd.to_datetime(str(price['date'].iloc[i])+str(price['time'].iloc[i]), format='%Y%m%d%H%M')\n",
    "        pbar.update(1)\n",
    "        \n",
    "# sort in ascending order\n",
    "reply = reply.sort_values(by='Date').reset_index(drop=True)\n",
    "price = price.sort_values(by='time').reset_index(drop=True)\n",
    "reply.index = reply['Date']\n",
    "reply = reply.drop(['Date'], axis=1)\n",
    "price.index = price['time']\n",
    "pirce = price.drop(['date', 'time'], axis=1)\n",
    "\n",
    "display(reply)\n",
    "display(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-31 09:01:00\n",
      "2019-11-12 15:30:00\n"
     ]
    }
   ],
   "source": [
    "day_start = max(price.index[0], reply.index[0])\n",
    "day_end = min(price.index[-1], reply.index[-1])\n",
    "print(day_start)\n",
    "print(day_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Views</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Like</th>\n",
       "      <th>Unlike</th>\n",
       "      <th>Ip</th>\n",
       "      <th>close</th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>time</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:01:00</td>\n",
       "      <td>192.0</td>\n",
       "      <td>계엄령 문건 덮었다는 '윤석열 직인'···알고보니 자동 출력</td>\n",
       "      <td>\\r\\n이젠 호모쉐퀴들도 부역자 노릇을 하는구나\\r\\r\\n \\r\\n군대도 안다녀온...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125.178.***.115</td>\n",
       "      <td>50900.0</td>\n",
       "      <td>20191031.0</td>\n",
       "      <td>51100.0</td>\n",
       "      <td>50900.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>2019-10-31 09:01:00</td>\n",
       "      <td>580976.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:01:00</td>\n",
       "      <td>544.0</td>\n",
       "      <td>오늘 실적발표 일...</td>\n",
       "      <td>자료는 공개되었네요\\r\\r\\n못보신 분들은 확인하세요\\r\\r\\n \\r\\nhttps:...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.216.***.242</td>\n",
       "      <td>50900.0</td>\n",
       "      <td>20191031.0</td>\n",
       "      <td>51100.0</td>\n",
       "      <td>50900.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>2019-10-31 09:01:00</td>\n",
       "      <td>580976.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:03:00</td>\n",
       "      <td>135.0</td>\n",
       "      <td>지금은 `폴더블폰` 시대…화면 확장 한계 넘는다ㅋ</td>\n",
       "      <td>ㅋㅋ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.62.***.176</td>\n",
       "      <td>51100.0</td>\n",
       "      <td>20191031.0</td>\n",
       "      <td>51100.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>51100.0</td>\n",
       "      <td>2019-10-31 09:03:00</td>\n",
       "      <td>13198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:04:00</td>\n",
       "      <td>148.0</td>\n",
       "      <td>삼성, 새로운 폴더블폰 공개…'갤럭시 폴드는 시작일 뿐'ㅋ</td>\n",
       "      <td>ㅋㅋ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.62.***.176</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>20191031.0</td>\n",
       "      <td>51100.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>51100.0</td>\n",
       "      <td>2019-10-31 09:04:00</td>\n",
       "      <td>37929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-10-31 09:05:00</td>\n",
       "      <td>203.0</td>\n",
       "      <td>삼성, 내년 폴더블폰 판매 10배 이상 늘린다…최대 600만대 달할 듯ㅋ</td>\n",
       "      <td>ㅋㅋ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.62.***.176</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>20191031.0</td>\n",
       "      <td>51100.0</td>\n",
       "      <td>50900.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>2019-10-31 09:05:00</td>\n",
       "      <td>83816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:16:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>20191112.0</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52400.0</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>2019-11-12 15:16:00</td>\n",
       "      <td>15225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>20191112.0</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52400.0</td>\n",
       "      <td>52400.0</td>\n",
       "      <td>2019-11-12 15:18:00</td>\n",
       "      <td>20269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:19:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>20191112.0</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52400.0</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>2019-11-12 15:19:00</td>\n",
       "      <td>18480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>20191112.0</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>52400.0</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>2019-11-12 15:20:00</td>\n",
       "      <td>47526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-12 15:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52600.0</td>\n",
       "      <td>20191112.0</td>\n",
       "      <td>52600.0</td>\n",
       "      <td>52600.0</td>\n",
       "      <td>52600.0</td>\n",
       "      <td>2019-11-12 15:30:00</td>\n",
       "      <td>832746.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8150 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Views                                     Title  \\\n",
       "key_0                                                                  \n",
       "2019-10-31 09:01:00  192.0         계엄령 문건 덮었다는 '윤석열 직인'···알고보니 자동 출력   \n",
       "2019-10-31 09:01:00  544.0                              오늘 실적발표 일...   \n",
       "2019-10-31 09:03:00  135.0               지금은 `폴더블폰` 시대…화면 확장 한계 넘는다ㅋ   \n",
       "2019-10-31 09:04:00  148.0          삼성, 새로운 폴더블폰 공개…'갤럭시 폴드는 시작일 뿐'ㅋ   \n",
       "2019-10-31 09:05:00  203.0  삼성, 내년 폴더블폰 판매 10배 이상 늘린다…최대 600만대 달할 듯ㅋ   \n",
       "...                    ...                                       ...   \n",
       "2019-11-12 15:16:00    NaN                                       NaN   \n",
       "2019-11-12 15:18:00    NaN                                       NaN   \n",
       "2019-11-12 15:19:00    NaN                                       NaN   \n",
       "2019-11-12 15:20:00    NaN                                       NaN   \n",
       "2019-11-12 15:30:00    NaN                                       NaN   \n",
       "\n",
       "                                                               Content  Like  \\\n",
       "key_0                                                                          \n",
       "2019-10-31 09:01:00   \\r\\n이젠 호모쉐퀴들도 부역자 노릇을 하는구나\\r\\r\\n \\r\\n군대도 안다녀온...   6.0   \n",
       "2019-10-31 09:01:00  자료는 공개되었네요\\r\\r\\n못보신 분들은 확인하세요\\r\\r\\n \\r\\nhttps:...   0.0   \n",
       "2019-10-31 09:03:00                                                 ㅋㅋ   0.0   \n",
       "2019-10-31 09:04:00                                                 ㅋㅋ   0.0   \n",
       "2019-10-31 09:05:00                                                 ㅋㅋ   3.0   \n",
       "...                                                                ...   ...   \n",
       "2019-11-12 15:16:00                                                NaN   NaN   \n",
       "2019-11-12 15:18:00                                                NaN   NaN   \n",
       "2019-11-12 15:19:00                                                NaN   NaN   \n",
       "2019-11-12 15:20:00                                                NaN   NaN   \n",
       "2019-11-12 15:30:00                                                NaN   NaN   \n",
       "\n",
       "                     Unlike               Ip    close        date     high  \\\n",
       "key_0                                                                        \n",
       "2019-10-31 09:01:00     4.0  125.178.***.115  50900.0  20191031.0  51100.0   \n",
       "2019-10-31 09:01:00     0.0  112.216.***.242  50900.0  20191031.0  51100.0   \n",
       "2019-10-31 09:03:00     0.0   223.62.***.176  51100.0  20191031.0  51100.0   \n",
       "2019-10-31 09:04:00     0.0   223.62.***.176  51000.0  20191031.0  51100.0   \n",
       "2019-10-31 09:05:00     0.0   223.62.***.176  51000.0  20191031.0  51100.0   \n",
       "...                     ...              ...      ...         ...      ...   \n",
       "2019-11-12 15:16:00     NaN              NaN  52500.0  20191112.0  52500.0   \n",
       "2019-11-12 15:18:00     NaN              NaN  52500.0  20191112.0  52500.0   \n",
       "2019-11-12 15:19:00     NaN              NaN  52500.0  20191112.0  52500.0   \n",
       "2019-11-12 15:20:00     NaN              NaN  52500.0  20191112.0  52500.0   \n",
       "2019-11-12 15:30:00     NaN              NaN  52600.0  20191112.0  52600.0   \n",
       "\n",
       "                         low     open                 time       vol  \n",
       "key_0                                                                 \n",
       "2019-10-31 09:01:00  50900.0  51000.0  2019-10-31 09:01:00  580976.0  \n",
       "2019-10-31 09:01:00  50900.0  51000.0  2019-10-31 09:01:00  580976.0  \n",
       "2019-10-31 09:03:00  51000.0  51100.0  2019-10-31 09:03:00   13198.0  \n",
       "2019-10-31 09:04:00  51000.0  51100.0  2019-10-31 09:04:00   37929.0  \n",
       "2019-10-31 09:05:00  50900.0  51000.0  2019-10-31 09:05:00   83816.0  \n",
       "...                      ...      ...                  ...       ...  \n",
       "2019-11-12 15:16:00  52400.0  52500.0  2019-11-12 15:16:00   15225.0  \n",
       "2019-11-12 15:18:00  52400.0  52400.0  2019-11-12 15:18:00   20269.0  \n",
       "2019-11-12 15:19:00  52400.0  52500.0  2019-11-12 15:19:00   18480.0  \n",
       "2019-11-12 15:20:00  52400.0  52500.0  2019-11-12 15:20:00   47526.0  \n",
       "2019-11-12 15:30:00  52600.0  52600.0  2019-11-12 15:30:00  832746.0  \n",
       "\n",
       "[8150 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# merge dataframe\n",
    "reply_common = reply[(reply.index >= day_start) & (reply.index <= day_end)]\n",
    "price_common = price[(price.index >= day_start) & (price.index <= day_end)]\n",
    "df = reply_common.merge(price_common, how='outer', left_on=reply_common.index, right_on=price_common.index)\n",
    "df.index = df['key_0']\n",
    "df = df.drop(['key_0'], axis=1)\n",
    "display(df)\n",
    "\n",
    "# check intersection of timestamp\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(price.index, np.zeros(price.shape[0]), label='price')\n",
    "plt.plot(reply.index, np.ones(reply.shape[0]), label='reply')\n",
    "plt.plot(df.index, np.full(df.shape[0], 2), label='merged df')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertRegressor(nn.Module) : \n",
    "    def __init__(self) : \n",
    "        super(BertRegressor, self).__init__()\n",
    "        self.bert, self.vocab = get_pytorch_kobert_model()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "    \n",
    "    def forward(self, tokens) : \n",
    "        _, pooled_output = self.bert(tokens, utput_all=False)\n",
    "        linear_output = self.relu(pooled_output)\n",
    "        predicted_price = self.linear(linear_output)\n",
    "\n",
    "        return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertRegressor(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_reg = BertRegressor()\n",
    "bert_reg.to(device)\n",
    "optimizer = torch.optim.Adam(bert_reg.parameters(), lr=3e-6)\n",
    "bert_reg.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
